{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clPcl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f6c4716b5b148f89f64f6e86a0eea90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87c93783697c4ae6bb11caed54d35ab0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a95974bed1e14494bc35c97954be45e0",
              "IPY_MODEL_1a735f43dd5e43518a1caaf8d8545b55",
              "IPY_MODEL_bdaac8a2f17a4a019dc289496c97b15a"
            ]
          }
        },
        "87c93783697c4ae6bb11caed54d35ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a95974bed1e14494bc35c97954be45e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5404f16b62c34f058cf3e2205c6b8c58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fef31725441a4aa7b255b88a3cc017b5"
          }
        },
        "1a735f43dd5e43518a1caaf8d8545b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d644b2d3ffbe41a7b5c94ae16b955baa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2640397119,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2640397119,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40d67c269cda4f30ba39a6a1f93afe17"
          }
        },
        "bdaac8a2f17a4a019dc289496c97b15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c04ddc159c8e4b768d5ef2b59f486e04",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2640397312/? [02:19&lt;00:00, 22320794.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c3541f0ddbd48f8a5faa1dddbdcb667"
          }
        },
        "5404f16b62c34f058cf3e2205c6b8c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fef31725441a4aa7b255b88a3cc017b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d644b2d3ffbe41a7b5c94ae16b955baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40d67c269cda4f30ba39a6a1f93afe17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c04ddc159c8e4b768d5ef2b59f486e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c3541f0ddbd48f8a5faa1dddbdcb667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MT-Blachetta/clPcl_SingleGPU/blob/main/clPcl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYz7J1jFQOZc",
        "outputId": "87345c1d-563f-477e-a261-f0267ad3a6b4"
      },
      "source": [
        "#!pip install spherecluster\n",
        "#!pip install scikit-learn==0.20.0\n",
        "!wget https://github.com/MT-Blachetta/clPcl_SingleGPU/archive/refs/heads/main.zip\n",
        "!unzip main.zip\n",
        "!rm main.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-29 23:01:06--  https://github.com/MT-Blachetta/clPcl_SingleGPU/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/MT-Blachetta/clPcl_SingleGPU/zip/refs/heads/main [following]\n",
            "--2021-11-29 23:01:07--  https://codeload.github.com/MT-Blachetta/clPcl_SingleGPU/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [  <=>               ]   2.75M  9.16MB/s    in 0.3s    \n",
            "\n",
            "2021-11-29 23:01:07 (9.16 MB/s) - ‘main.zip’ saved [2888241]\n",
            "\n",
            "Archive:  main.zip\n",
            "31253cfa3fe812485bdf438a2a8498d86290b636\n",
            "   creating: clPcl_SingleGPU-main/\n",
            "  inflating: clPcl_SingleGPU-main/LICENSE  \n",
            "  inflating: clPcl_SingleGPU-main/README.md  \n",
            "   creating: clPcl_SingleGPU-main/RESULTS/\n",
            "   creating: clPcl_SingleGPU-main/RESULTS/mnist/\n",
            "   creating: clPcl_SingleGPU-main/RESULTS/mnist/pretext/\n",
            "  inflating: clPcl_SingleGPU-main/RESULTS/mnist/pretext/checkpoint.pth.tar  \n",
            "  inflating: clPcl_SingleGPU-main/RESULTS/mnist/pretext/model.pth.tar  \n",
            "  inflating: clPcl_SingleGPU-main/clPcl.ipynb  \n",
            "   creating: clPcl_SingleGPU-main/configs/\n",
            " extracting: clPcl_SingleGPU-main/configs/env.yml  \n",
            "   creating: clPcl_SingleGPU-main/configs/pretext/\n",
            "  inflating: clPcl_SingleGPU-main/configs/pretext/clPcl_stl10.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/pretext/moco_imagenet100.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/pretext/moco_imagenet200.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/pretext/moco_imagenet50.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/pretext/simclr_cifar10.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/pretext/simclr_cifar20.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/pretext/simclr_mnist.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/pretext/simclr_stl10.yml  \n",
            "   creating: clPcl_SingleGPU-main/configs/scan/\n",
            "  inflating: clPcl_SingleGPU-main/configs/scan/imagenet_eval.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/scan/scan_cifar10.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/scan/scan_cifar20.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/scan/scan_imagenet_100.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/scan/scan_imagenet_200.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/scan/scan_imagenet_50.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/scan/scan_mnist.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/scan/scan_stl10.yml  \n",
            "   creating: clPcl_SingleGPU-main/configs/selflabel/\n",
            "  inflating: clPcl_SingleGPU-main/configs/selflabel/selflabel_cifar10.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/selflabel/selflabel_cifar20.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/selflabel/selflabel_imagenet_100.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/selflabel/selflabel_imagenet_200.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/selflabel/selflabel_imagenet_50.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/selflabel/selflabel_mnist.yml  \n",
            "  inflating: clPcl_SingleGPU-main/configs/selflabel/selflabel_stl10.yml  \n",
            "   creating: clPcl_SingleGPU-main/data/\n",
            "   creating: clPcl_SingleGPU-main/data/__pycache__/\n",
            "  inflating: clPcl_SingleGPU-main/data/__pycache__/augment.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/data/__pycache__/custom_dataset.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/data/__pycache__/mnist.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/data/__pycache__/stl.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/data/augment.py  \n",
            "  inflating: clPcl_SingleGPU-main/data/cifar.py  \n",
            "  inflating: clPcl_SingleGPU-main/data/custom_dataset.py  \n",
            "  inflating: clPcl_SingleGPU-main/data/imagenet.py  \n",
            "   creating: clPcl_SingleGPU-main/data/imagenet_subsets/\n",
            "  inflating: clPcl_SingleGPU-main/data/imagenet_subsets/imagenet_100.txt  \n",
            "  inflating: clPcl_SingleGPU-main/data/imagenet_subsets/imagenet_200.txt  \n",
            "  inflating: clPcl_SingleGPU-main/data/imagenet_subsets/imagenet_50.txt  \n",
            "  inflating: clPcl_SingleGPU-main/data/mnist.py  \n",
            "  inflating: clPcl_SingleGPU-main/data/stl.py  \n",
            "   creating: clPcl_SingleGPU-main/dataset/\n",
            "   creating: clPcl_SingleGPU-main/dataset/MNIST/\n",
            "   creating: clPcl_SingleGPU-main/dataset/MNIST/processed/\n",
            "  inflating: clPcl_SingleGPU-main/dataset/MNIST/processed/test.pt  \n",
            "   creating: clPcl_SingleGPU-main/images/\n",
            "  inflating: clPcl_SingleGPU-main/images/illustration.jpg  \n",
            "   creating: clPcl_SingleGPU-main/logs/\n",
            "  inflating: clPcl_SingleGPU-main/logs/scan_stl10.txt  \n",
            "   creating: clPcl_SingleGPU-main/losses/\n",
            "   creating: clPcl_SingleGPU-main/losses/__pycache__/\n",
            "  inflating: clPcl_SingleGPU-main/losses/__pycache__/losses.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/losses/losses.py  \n",
            "  inflating: clPcl_SingleGPU-main/moco.py  \n",
            "   creating: clPcl_SingleGPU-main/models/\n",
            "   creating: clPcl_SingleGPU-main/models/__pycache__/\n",
            "  inflating: clPcl_SingleGPU-main/models/__pycache__/mnet.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/models/__pycache__/models.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/models/__pycache__/resnet_stl.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/models/clPcl_model.py  \n",
            "  inflating: clPcl_SingleGPU-main/models/mnet.py  \n",
            "  inflating: clPcl_SingleGPU-main/models/models.py  \n",
            "  inflating: clPcl_SingleGPU-main/models/resnet.py  \n",
            "  inflating: clPcl_SingleGPU-main/models/resnet_cifar.py  \n",
            "  inflating: clPcl_SingleGPU-main/models/resnet_stl.py  \n",
            "  inflating: clPcl_SingleGPU-main/pcPcl_execution.ipynb  \n",
            "  inflating: clPcl_SingleGPU-main/pcl_cld.py  \n",
            "  inflating: clPcl_SingleGPU-main/requirements.txt  \n",
            "  inflating: clPcl_SingleGPU-main/run_pcPcl.ipynb  \n",
            "  inflating: clPcl_SingleGPU-main/scan.py  \n",
            "  inflating: clPcl_SingleGPU-main/selflabel.py  \n",
            "   creating: clPcl_SingleGPU-main/utils/\n",
            "   creating: clPcl_SingleGPU-main/utils/__pycache__/\n",
            "  inflating: clPcl_SingleGPU-main/utils/__pycache__/collate.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/utils/__pycache__/common_config.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/utils/__pycache__/config.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/utils/__pycache__/evaluate_utils.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/utils/__pycache__/memory.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/utils/__pycache__/mypath.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/utils/__pycache__/train_utils.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/utils/__pycache__/utils.cpython-37.pyc  \n",
            "  inflating: clPcl_SingleGPU-main/utils/collate.py  \n",
            "  inflating: clPcl_SingleGPU-main/utils/common_config.py  \n",
            "  inflating: clPcl_SingleGPU-main/utils/config.py  \n",
            "  inflating: clPcl_SingleGPU-main/utils/ema.py  \n",
            "  inflating: clPcl_SingleGPU-main/utils/evaluate_utils.py  \n",
            "  inflating: clPcl_SingleGPU-main/utils/memory.py  \n",
            "  inflating: clPcl_SingleGPU-main/utils/mypath.py  \n",
            "  inflating: clPcl_SingleGPU-main/utils/train_utils.py  \n",
            "  inflating: clPcl_SingleGPU-main/utils/utils.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEn8wY6ZJItE"
      },
      "source": [
        "#--config_env configs/env.yml \n",
        "#--config_exp configs/pretext/clPcl_stl10.yml\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from utils.config import create_config\n",
        "from utils.common_config import get_criterion, get_backbone_model , get_instance_model,get_group_model, get_train_dataset,\\\n",
        "                                get_val_dataset, get_train_dataloader,\\\n",
        "                                get_val_dataloader, get_train_transformations,\\\n",
        "                                get_val_transformations, get_optimizer,\\\n",
        "                                adjust_learning_rate, get_clustering\n",
        "from utils.evaluate_utils import contrastive_evaluate\n",
        "from utils.memory import MemoryBank\n",
        "from utils.train_utils import pcl_cld_train\n",
        "from utils.utils import fill_memory_bank\n",
        "from termcolor import colored"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge-VUFnklnzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62aca005-e476-4241-e9ab-21945f23e4c7"
      },
      "source": [
        "    #1# Retrieve config file\n",
        "p = create_config(\"configs/env.yml\", \"configs/pretext/clPcl_stl10.yml\")\n",
        "print(colored(p, 'red'))\n",
        "print(colored('Retrieve model', 'blue'))\n",
        "    \n",
        "backbone = get_backbone_model(p)\n",
        "print('Model is {}'.format(backbone.__class__.__name__))\n",
        "#print('Model parameters: {:.2f}M'.format(sum(p.numel() for p in backbone.parameters()) / 1e6))\n",
        "print(backbone)\n",
        "    \n",
        "    \n",
        "instance_model = get_instance_model(p, backbone)\n",
        "instance_head = instance_model.get_head()\n",
        "    \n",
        "group_model = get_group_model(p, backbone)\n",
        "group_head = group_model.get_head()\n",
        "backbone_model = group_model.get_backbone()\n",
        "print('Model is {}'.format(instance_model.__class__.__name__))\n",
        "print('Model parameters: {:.2f}M'.format(sum(p.numel() for p in instance_model.parameters()) / 1e6))\n",
        "print(instance_model)\n",
        "print('Model is {}'.format(group_model.__class__.__name__))\n",
        "print('Model parameters: {:.2f}M'.format(sum(p.numel() for p in group_model.parameters()) / 1e6))\n",
        "print(group_model)\n",
        "    #instance_model = instance_model.cuda()\n",
        "    #group_model = group_model.cuda()\n",
        "   \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m{'setup': 'clPcl', 'clustering': [2, 4, 8, 16], 'backbone': 'resnet18', 'model_kwargs': {'head': 'linear', 'features_dim': 128}, 'train_db_name': 'stl-10', 'val_db_name': 'stl-10', 'num_classes': 10, 'criterion': 'clPcl', 'criterion_kwargs': {'temperature': 0.1}, 'epochs': 500, 'optimizer': 'sgd', 'optimizer_kwargs': {'nesterov': False, 'weight_decay': 0.0001, 'momentum': 0.9, 'lr': 0.4}, 'scheduler': 'cosine', 'scheduler_kwargs': {'lr_decay_rate': 0.1}, 'batch_size': 512, 'num_workers': 0, 'augmentation_strategy': 'simclr', 'augmentation_kwargs': {'random_resized_crop': {'size': 96, 'scale': [0.2, 1.0]}, 'color_jitter_random_apply': {'p': 0.8}, 'color_jitter': {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}, 'random_grayscale': {'p': 0.2}, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'transformation_kwargs': {'crop_size': 96, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'pretext_dir': 'RESULTS/stl-10/pretext', 'pretext_checkpoint': 'RESULTS/stl-10/pretext/checkpoint.pth.tar', 'pretext_checkpoint_backbone': 'RESULTS/stl-10/pretext/backbone_checkpoint.pth.tar', 'pretext_checkpoint_instance': 'RESULTS/stl-10/pretext/instance_checkpoint.pth.tar', 'pretext_checkpoint_group': 'RESULTS/stl-10/pretext/group_checkpoint.pth.tar', 'pretext_model': 'RESULTS/stl-10/pretext/model.pth.tar', 'pretext_model_instance': 'RESULTS/stl-10/pretext/instance_model.pth.tar', 'pretext_model_group': 'RESULTS/stl-10/pretext/group_model.pth.tar', 'topk_neighbors_train_path': 'RESULTS/stl-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': 'RESULTS/stl-10/pretext/topk-val-neighbors.npy'}\u001b[0m\n",
            "\u001b[34mRetrieve model\u001b[0m\n",
            "Model is dict\n",
            "{'backbone': ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "), 'dim': 512}\n",
            "Model is MoCo\n",
            "Model parameters: 22.47M\n",
            "MoCo(\n",
            "  (encoder_q): ContrastiveModel(\n",
            "    (backbone): ResNet(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "    )\n",
            "    (contrastive_head): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
            "  )\n",
            "  (encoder_k): ContrastiveModel(\n",
            "    (backbone): ResNet(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (shortcut): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "    )\n",
            "    (contrastive_head): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
            "  )\n",
            ")\n",
            "Model is ContrastiveModel\n",
            "Model parameters: 11.23M\n",
            "ContrastiveModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "  )\n",
            "  (contrastive_head): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc): Linear(in_features=512, out_features=128, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coZEx4q7tBAT",
        "outputId": "7db81e4f-8f3a-44e2-e614-1e9f537d9f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657,
          "referenced_widgets": [
            "1f6c4716b5b148f89f64f6e86a0eea90",
            "87c93783697c4ae6bb11caed54d35ab0",
            "a95974bed1e14494bc35c97954be45e0",
            "1a735f43dd5e43518a1caaf8d8545b55",
            "bdaac8a2f17a4a019dc289496c97b15a",
            "5404f16b62c34f058cf3e2205c6b8c58",
            "fef31725441a4aa7b255b88a3cc017b5",
            "d644b2d3ffbe41a7b5c94ae16b955baa",
            "40d67c269cda4f30ba39a6a1f93afe17",
            "c04ddc159c8e4b768d5ef2b59f486e04",
            "7c3541f0ddbd48f8a5faa1dddbdcb667"
          ]
        }
      },
      "source": [
        "     #> CUDNN\n",
        "print(colored('Set CuDNN benchmark', 'blue')) \n",
        "torch.backends.cudnn.benchmark = True    \n",
        "    ###\n",
        "\n",
        "\n",
        "#3# Dataset                                                       OK\n",
        "    #A - get transformormations for the dataset\n",
        "print(colored('Retrieve dataset', 'blue'))\n",
        "train_transforms = get_train_transformations(p) \n",
        "print('Train transforms:', train_transforms)\n",
        "val_transforms = get_val_transformations(p)\n",
        "    \n",
        "    #B - get Dataset from files\n",
        "print('Validation transforms:', val_transforms)\n",
        "split_ = 'train'\n",
        "\n",
        "if p['train_db_name'] == 'stl-10': \n",
        "  split_ = 'train+unlabeled'\n",
        "\n",
        "train_dataset = get_train_dataset(p, train_transforms, to_augmented_dataset=True,\n",
        "                                        split=split_) # Split is for stl-10\n",
        "                                        \n",
        "val_dataset = get_val_dataset(p, val_transforms)\n",
        "    \n",
        "#C - put the dataset to the dataloader for training purposes\n",
        "train_dataloader = get_train_dataloader(p, train_dataset)\n",
        "val_dataloader = get_val_dataloader(p, val_dataset)\n",
        "print('Dataset contains {}/{} train/val samples'.format(len(train_dataset), len(val_dataset)))\n",
        "        #4# Memory Bank\n",
        "print(colored('Build MemoryBank', 'blue'))\n",
        "base_dataset = get_train_dataset(p, val_transforms, split='train') # Dataset w/o augs for knn eval\n",
        "base_dataloader = get_val_dataloader(p, base_dataset) \n",
        "    \n",
        "memory_bank_base = MemoryBank(len(base_dataset), \n",
        "                                p['model_kwargs']['features_dim'],\n",
        "                                p['num_classes'], p['criterion_kwargs']['temperature'])\n",
        "\n",
        "    \n",
        "memory_bank_val = MemoryBank(len(val_dataset),\n",
        "                                p['model_kwargs']['features_dim'],\n",
        "                                p['num_classes'], p['criterion_kwargs']['temperature'])\n",
        "\n",
        "iloss = torch.nn.CrossEntropyLoss()\n",
        "iloss.cuda()\n",
        "\n",
        "# Criterion\n",
        "print(colored('Retrieve criterion', 'blue'))\n",
        "criterion = get_criterion(p)\n",
        "print('Criterion is {}'.format(criterion.__class__.__name__))\n",
        "criterion = criterion.cuda()\n",
        "\n",
        "    # Optimizer and scheduler                                       \n",
        "print(colored('Retrieve optimizer', 'blue'))\n",
        "optimizer = get_optimizer(p, group_model)\n",
        "print(optimizer)\n",
        "    ###\n",
        "M_num_clusters = get_clustering(p)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mSet CuDNN benchmark\u001b[0m\n",
            "\u001b[34mRetrieve dataset\u001b[0m\n",
            "Train transforms: Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "Validation transforms: Compose(\n",
            "    CenterCrop(size=(96, 96))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to /dataset/stl-10/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f6c4716b5b148f89f64f6e86a0eea90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2640397119 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /dataset/stl-10/stl10_binary.tar.gz to /dataset/stl-10/\n",
            "Files already downloaded and verified\n",
            "Dataset contains 10000/8000 train/val samples\n",
            "\u001b[34mBuild MemoryBank\u001b[0m\n",
            "Files already downloaded and verified\n",
            "\u001b[34mRetrieve criterion\u001b[0m\n",
            "Criterion is PclCldLoss\n",
            "\u001b[34mRetrieve optimizer\u001b[0m\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.4\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0001\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnxfd2FkuE0M",
        "outputId": "0f1b0bce-a882-44f9-d7ce-8b2f671c168d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "    #6# Checkpoint to continue last training phase                             OK\n",
        "if os.path.exists(p['pretext_checkpoint_backbone']):\n",
        "  print(colored('Restart from checkpoint (backbone) {}'.format(p['pretext_checkpoint_backbone']), 'blue'))\n",
        "  checkpoint = torch.load(p['pretext_checkpoint_backbone'], map_location='cpu')\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  backbone_model.load_state_dict(checkpoint['model'])\n",
        "  instance_model.set_backbone(backbone_model)\n",
        "  group_model.set_backbone(backbone_model)\n",
        "        #backbone.cuda()\n",
        "  start_epoch = checkpoint['epoch']\n",
        "\n",
        "else:\n",
        "  print(colored('No checkpoint file at {}'.format(p['pretext_checkpoint_backbone']), 'blue'))\n",
        "  start_epoch = 0\n",
        "      \n",
        "  \n",
        "if os.path.exists(p['pretext_checkpoint_instance']):\n",
        "  print(colored('Restart from checkpoint (instance_model) {}'.format(p['pretext_checkpoint_instance']), 'blue'))\n",
        "  checkpoint = torch.load(p['pretext_checkpoint_instance'], map_location='cpu')\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  instance_head.load_state_dict(checkpoint['model'])  \n",
        "        \n",
        "  instance_model.set_head(instance_head)\n",
        "  instance_model = instance_model.cuda()\n",
        "  start_epoch = checkpoint['epoch']\n",
        "\n",
        "else:\n",
        "  print(colored('No checkpoint file at {}'.format(p['pretext_checkpoint_instance']), 'blue'))\n",
        "  start_epoch = 0\n",
        "  instance_model = instance_model.cuda()\n",
        "        \n",
        "if os.path.exists(p['pretext_checkpoint_group']):\n",
        "  print(colored('Restart from checkpoint (group_model) {}'.format(p['pretext_checkpoint_group']), 'blue'))\n",
        "  checkpoint = torch.load(p['pretext_checkpoint_group'], map_location='cpu')\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  group_head.load_state_dict(checkpoint['model'])\n",
        "\t\n",
        "  group_model.set_head(group_head)\n",
        "  group_model = group_model.cuda()\n",
        "  start_epoch = checkpoint['epoch']\n",
        "        \n",
        "else:\n",
        "  print(colored('No checkpoint file at {}'.format(p['pretext_checkpoint_group']), 'blue'))\n",
        "  start_epoch = 0\n",
        "  group_model = group_model.cuda()\n",
        "        \n",
        "    ###"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mNo checkpoint file at RESULTS/stl-10/pretext/checkpoint.pth.tar\u001b[0m\n",
            "\u001b[34mNo checkpoint file at RESULTS/stl-10/pretext/checkpoint.pth.tar\u001b[0m\n",
            "\u001b[34mNo checkpoint file at RESULTS/stl-10/pretext/checkpoint.pth.tar\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5bP-h63weKS",
        "outputId": "68fbbee4-76ab-4757-fda2-1ed9d69c88e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "source": [
        "print(colored('Starting main loop', 'blue'))\n",
        "\n",
        "for epoch in range(start_epoch, p['epochs']):\n",
        "  print(colored('Epoch %d/%d' %(epoch, p['epochs']), 'yellow'))\n",
        "  print(colored('-'*15, 'yellow'))\n",
        "\n",
        "        #a - Adjust lr\n",
        "  lr = adjust_learning_rate(p, optimizer, epoch)\n",
        "  print('Adjusted learning rate to {:.5f}'.format(lr))\n",
        "        \n",
        "        #b - Train the model with the clPcl method for one epoch (iteration)\n",
        "  print('Train ...')\n",
        "  pcl_cld_train(train_loader = train_dataloader, instance_branch = instance_model, group_branch = group_model, criterion = criterion, optimizer = optimizer, epoch = epoch, M_num_clusters = M_num_clusters)\n",
        "\n",
        "        #c - Fill memory bank (Data Structure for nearest neighbors of input-instances)\n",
        "  print('Fill memory bank for kNN...')\n",
        "  fill_memory_bank(base_dataloader, group_model, memory_bank_base)\n",
        "\n",
        "        #d - Evaluate (To monitor progress - Not for validation)\n",
        "  print('Evaluate ...')\n",
        "  top1 = contrastive_evaluate(val_dataloader, group_model, memory_bank_base)\n",
        "  print('Result of kNN evaluation is %.2f' %(top1)) \n",
        "        \n",
        "        #e - Checkpoint\n",
        "  print('Checkpoint ...')\n",
        "        \n",
        "  torch.save({'optimizer': optimizer.state_dict(), 'model': group_model.get_backbone().state_dict(), \n",
        "                    'epoch': epoch + 1}, p['pretext_checkpoint_backbone'])\n",
        "        \n",
        "  torch.save({'optimizer': optimizer.state_dict(), 'model': instance_model.get_head().state_dict(), \n",
        "                    'epoch': epoch + 1}, p['pretext_checkpoint_instance'])\n",
        "                    \n",
        "  torch.save({'optimizer': optimizer.state_dict(), 'model': group_model.get_head().state_dict(), \n",
        "                    'epoch': epoch + 1}, p['pretext_checkpoint_group'])\n",
        "                    \n",
        "        \n",
        "\n",
        "    # Save final model\n",
        "  torch.save(instance_model.state_dict(), p['pretext_model_instance'])\n",
        "  torch.save(group_model.state_dict(),p['pretext_model_group'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mStarting main loop\u001b[0m\n",
            "\u001b[33mEpoch 0/500\u001b[0m\n",
            "\u001b[33m---------------\u001b[0m\n",
            "Adjusted learning rate to 0.40000\n",
            "Train ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-524c0b3232e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#b - Train the model with the clPcl method for one epoch (iteration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mpcl_cld_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_num_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_num_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#c - Fill memory bank (Data Structure for nearest neighbors of input-instances)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils/train_utils.py\u001b[0m in \u001b[0;36mpcl_cld_train\u001b[0;34m(train_loader, instance_branch, group_branch, criterion, optimizer, epoch, M_num_clusters)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0maugmentedImage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentedImage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginImage_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maugmentedImage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0minstance_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/clPcl_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, im_q, im_k)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m#im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_k\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keys: NxC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrastive_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/resnet_stl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.12 GiB (GPU 0; 11.17 GiB total capacity; 9.37 GiB already allocated; 520.81 MiB free; 10.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycvf_AMnwYfh"
      },
      "source": [
        "# single run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzR7syJ3mURp",
        "outputId": "53694ff8-479b-4ff7-f69f-70d0f78265a3"
      },
      "source": [
        "        #7# Training\n",
        "print(colored('Starting main loop', 'blue'))\n",
        "#for epoch in range(start_epoch, 1):\n",
        "    #print(colored('Epoch %d/%d' %(epoch, p['epochs']), 'yellow'))\n",
        "    #print(colored('-'*15, 'yellow'))\n",
        "\n",
        "        #a - Adjust lr\n",
        "lr = adjust_learning_rate(p, optimizer, 1)\n",
        "print('Adjusted learning rate to {:.5f}'.format(lr))\n",
        "        \n",
        "        #b - Train the model with the clPcl method for one epoch (iteration)\n",
        "print('Train ...')\n",
        "#def pcl_cld_train(args, train_loader, instance_branch, group_branch, criterion, optimizer, epoch, M_num_clusters):\n",
        "import torch\n",
        "import numpy as np\n",
        "#from spherecluster import VonMisesFisherMixture\n",
        "import nltk\n",
        "from nltk.cluster.kmeans import KMeansClusterer\n",
        "from utils.utils import AverageMeter, ProgressMeter\n",
        "#backbone = get_backbone_model(p)\n",
        "#instance_model = get_instance_model(p, backbone)\n",
        "#group_model = get_group_model(p, backbone)\n",
        "#losses = AverageMeter('Loss', ':.4e')\n",
        "#progress = ProgressMeter(len(train_dataloader),[losses],prefix=\"Epoch: [{}]\".format(1))\n",
        "        \n",
        "instance_model.train()\n",
        "group_model.train()\n",
        "#instance_model = instance_model.cuda()\n",
        "#group_model = group_model.cuda()\n",
        "print(\"initialized pcl_cld_train\")\n",
        "\n",
        "i = 1\n",
        "batch = next(iter(train_dataloader))\n",
        "originImage_batch = batch['image']\n",
        "augmentedImage_batch = batch['image_augmented']\n",
        "originImage_batch = originImage_batch.cuda(non_blocking=True)\n",
        "augmentedImage_batch = augmentedImage_batch.cuda(non_blocking=True)\n",
        "print(\"batch_image_shape: \"+str(originImage_batch.shape))\n",
        "type(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mStarting main loop\u001b[0m\n",
            "Adjusted learning rate to 0.40000\n",
            "Train ...\n",
            "initialized pcl_cld_train\n",
            "batch_image_shape: torch.Size([64, 3, 96, 96])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6xdUb00WEVz",
        "outputId": "0fbcc4ad-f8df-4379-d233-31f4332f56bc"
      },
      "source": [
        "\n",
        "#print('Model is {}'.format(backbone.__class__.__name__))\n",
        "#print('Model parameters: {:.2f}M'.format(sum(p.numel() for p in backbone.parameters()) / 1e6))\n",
        "#print(backbone)\n",
        "#originImage_batch.cuda()\n",
        "#augmentedImage_batch.cuda()\n",
        "\n",
        "logits, labels = instance_model(originImage_batch,augmentedImage_batch)\n",
        "logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN MoCo->_dequeue_and_enqueue: batch_size = 64\n",
            "queue_ptr = 0\n",
            "next ptr = 64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[13.6168,  1.0472,  0.1281,  ..., -0.1120,  0.1565, -1.8276],\n",
              "        [13.7274,  1.5451, -0.0224,  ..., -0.9390, -0.2487, -1.7784],\n",
              "        [13.8654,  2.0759,  0.0908,  ..., -1.5972, -0.1473, -2.2851],\n",
              "        ...,\n",
              "        [12.9380,  1.9026,  0.2363,  ..., -1.4277,  0.0797, -1.6944],\n",
              "        [13.8260,  1.3726,  0.0316,  ..., -0.5932, -0.0624, -1.8486],\n",
              "        [13.8354,  1.0272,  0.1188,  ..., -0.5746,  0.0777, -2.1932]],\n",
              "       device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6BUjioDf-H6",
        "outputId": "678461a7-3ed2-49ad-8dc5-356540886408"
      },
      "source": [
        "#import torch.nn.functional as F\n",
        "#labels.cuda() \n",
        "#instance_loss = F.cross_entropy(logits,labels)\n",
        "instance_loss = iloss(logits,labels)\n",
        "instance_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2057, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO_p4xMI5GeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42413f2-8309-4d4c-e382-0220d536c69d"
      },
      "source": [
        "original_view = group_model(originImage_batch)\n",
        "augmented_view = group_model(augmentedImage_batch)\n",
        "\n",
        "M_kmeans_results = []\n",
        "MI_kmeans_results = []\n",
        "concentration_matrices = []\n",
        "concentration_matrices_I = []\n",
        "M_labels = []\n",
        "M_labels_I = []\n",
        "\n",
        "feature_dim = len(original_view[0])\n",
        "batch_size = len(original_view)\n",
        "\n",
        "# ov = original_view.cpu().detach().numpy()\n",
        "# av = augmented_view.cpu().detach().numpy()\n",
        "print(feature_dim)\n",
        "print(batch_size)\n",
        "print(original_view.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n",
            "64\n",
            "torch.Size([64, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myM-ssTh83ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ff9a80-33b3-4d67-81b2-b7f1ef54642c"
      },
      "source": [
        "from spherecluster import SphericalKMeans\n",
        "from utils.utils import AverageMeter, ProgressMeter\n",
        "import copy\n",
        "\n",
        "alpha = 0.1\n",
        "divzero = 0.1\n",
        "ov = original_view.cpu().detach().numpy()\n",
        "print(ov.shape)\n",
        "av = augmented_view.cpu().detach().numpy()\n",
        "\n",
        "for k in M_num_clusters:\n",
        "  #from spherecluster import SphericalKMeans\n",
        "  skm = SphericalKMeans(n_clusters=k)\n",
        "  skm.fit(ov)\n",
        "  skm_I = SphericalKMeans(n_clusters=k)\n",
        "  skm_I.fit(av)\n",
        "\n",
        "  M_kmeans_results.append(torch.Tensor(skm.cluster_centers_))\n",
        "  MI_kmeans_results.append(torch.Tensor(skm_I.cluster_centers_))\n",
        "            # c -> k\n",
        "  center = [ torch.Tensor(skm.cluster_centers_[i]) for i in range(len(skm.cluster_centers_)) ]\n",
        "  center_I = [ torch.Tensor(skm_I.cluster_centers_[i]) for i in range(len(skm_I.cluster_centers_)) ]\n",
        "  cdat = [ x.unsqueeze(0).expand(batch_size,feature_dim) for x in center]\n",
        "  cmatrix = torch.cat(cdat,1)\n",
        "  cdat_I = [ x.unsqueeze(0).expand(batch_size,feature_dim) for x in center_I]\n",
        "  cmatrix_I = torch.cat(cdat_I,1)\n",
        "\n",
        "  original_cpu = original_view.cpu()\n",
        "  augmented_cpu = augmented_view.cpu()          \n",
        "  fmatrix = torch.Tensor(copy.deepcopy(ov))\n",
        "  fmatrix_I = torch.Tensor(copy.deepcopy(av))\n",
        "  #fmatrix = copy.deepcopy(original_cpu)\n",
        "  #fmatrix_I = copy.deepcopy(augmented_cpu)\n",
        "\n",
        "  for _ in range(1,k): fmatrix = torch.cat((fmatrix,original_cpu),1)\n",
        "  for _ in range(1,k): fmatrix_I = torch.cat((fmatrix_I,augmented_cpu),1)\n",
        "                \n",
        "  cmatrix = cmatrix.cuda()\n",
        "  fmatrix = fmatrix.cuda()\n",
        "  cmatrix_I = cmatrix_I.cuda()\n",
        "  fmatrix_I = fmatrix_I.cuda()\n",
        "            \n",
        "  zmatrix = fmatrix-cmatrix\n",
        "  zmatrix = zmatrix*zmatrix\n",
        "  result = zmatrix.flatten(0).view(batch_size,k,feature_dim)\n",
        "  result = torch.sum(result,2)\n",
        "\n",
        "  zmatrix_I = fmatrix_I-cmatrix_I\n",
        "  zmatrix_I = zmatrix_I*zmatrix_I\n",
        "  result_I = zmatrix_I.flatten(0).view(batch_size,k,feature_dim)\n",
        "  result_I = torch.sum(result_I,2)\n",
        "  assign = torch.zeros(batch_size,k)\n",
        "  assign_I = torch.zeros(batch_size,k)\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    assign[i][ int(skm.labels_[i]) ] = 1\n",
        "    assign_I[i][ int(skm_I.labels_[i]) ] = 1\n",
        "                \n",
        "  assign = assign.cuda()\n",
        "  assign_I = assign_I.cuda()\n",
        "            \n",
        "  avgDistance = torch.sum(assign*result,0)\n",
        "  Z = torch.sum(assign,0) + 1\n",
        "  Zlog = torch.log(Z+alpha)\n",
        "  divisor = Z*Zlog\n",
        "  concentrations = (avgDistance/divisor) + divzero\n",
        "  concentrations = concentrations.cpu()\n",
        "            #avgDistance = avgDistance.cuda()\n",
        "            #divisor = divisor.cuda()\n",
        "  avgDistance_I = torch.sum(assign_I*result_I,0)\n",
        "  Z_I = torch.sum(assign_I,0) + 1\n",
        "  Zlog_I = torch.log(Z_I+alpha)\n",
        "  divisor_I = Z_I*Zlog_I\n",
        "  concentrations_I = (avgDistance_I/divisor_I) + divzero\n",
        "  concentrations_I = concentrations_I.cpu()\n",
        "            \n",
        "  concentration_matrices.append(concentrations)\n",
        "  concentration_matrices_I.append(concentrations_I)\n",
        "            \n",
        "  M_labels.append( skm.labels_ )\n",
        "  M_labels_I.append( skm_I.labels_ )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XptHZM6yKJPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b43978-6269-4f49-bcfb-75f40175f4a6"
      },
      "source": [
        "# concentration_matrices - list of Tensors\n",
        "# M_kmeans_results - list of Tensors\n",
        "# M_labels - list of numpy.ndarray's\n",
        "# features = original view = cuda-Tensor\n",
        "concentration_matrices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0.1138, 0.1156], grad_fn=<ToCopyBackward0>),\n",
              " tensor([0.1164, 0.1114, 0.1126, 0.1159], grad_fn=<ToCopyBackward0>),\n",
              " tensor([0.1115, 0.1150, 0.1143, 0.1157, 0.1159, 0.1136, 0.1106, 0.1000],\n",
              "        grad_fn=<ToCopyBackward0>),\n",
              " tensor([0.1106, 0.1120, 0.1000, 0.1139, 0.1095, 0.1096, 0.1072, 0.1093, 0.1132,\n",
              "         0.1000, 0.1133, 0.1000, 0.1103, 0.1000, 0.1127, 0.1000],\n",
              "        grad_fn=<ToCopyBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJXxpwbEP58Y"
      },
      "source": [
        "# **Group Loss (debugging)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHdO5P6SAE8i",
        "outputId": "f7e8b59c-6d74-4ae3-8d89-605cff8949f8"
      },
      "source": [
        "#group_loss = criterion\n",
        "#import math\n",
        "\n",
        "features = original_view \n",
        "features_I = augmented_view \n",
        "M_kmeans = M_kmeans_results  \n",
        "M_kmeans_I = MI_kmeans_results \n",
        "concentrations = concentration_matrices \n",
        "concentrations_I = concentration_matrices_I \n",
        "labels = M_labels \n",
        "labels_I = M_labels_I\n",
        "lb = 1\n",
        "M_num = len(concentrations)\n",
        "print(M_num)\n",
        "batch_size = features.size()[0]\n",
        "#batch_size = original_view.size()[0]\n",
        "M_kmeans = M_kmeans_results \n",
        "M_kmeans_I = MI_kmeans_results\n",
        "\n",
        "M_logits = []\n",
        "M_logits_I = []\n",
        "\n",
        "#if k == 2: print()\n",
        "        \n",
        "for k in range(M_num):\n",
        "  c = len(concentrations[k]) # c = num_clusters of Mk\n",
        "  M_cmatrix = torch.zeros(c,batch_size)\n",
        "  MI_cmatrix = torch.zeros(c,batch_size)\n",
        "  for i in range(c):\n",
        "    M_cmatrix[i,:] = 1/concentrations[k][i]\n",
        "    MI_cmatrix[i,:] = 1/concentrations_I[k][i]\n",
        "\n",
        "  #if k == 2: print(M_cmatrix)          \n",
        "  M_cmatrix = M_cmatrix.cuda()\n",
        "  MI_cmatrix = MI_cmatrix.cuda()     \n",
        "  centroids = M_kmeans[k].cuda()\n",
        "  centroids_I = M_kmeans_I[k].cuda()\n",
        "  gLoss_or = torch.mm(centroids,features_I.T) # OK \n",
        "  gLoss_au = torch.mm(centroids_I,features.T)\n",
        "  #gLoss_or = torch.mm(centroids,augmented_view.T) # OK \n",
        "  #gLoss_au = torch.mm(centroids_I,original_view.T)\n",
        "  print(\"gLoss_or type: \"+str(type(gLoss_or)) )\n",
        "  print(\"gLoss_or shape: \"+str(gLoss_or.shape) )\n",
        "#--------------------------------------------------------\n",
        "  summing_logits = gLoss_or * M_cmatrix # OK\n",
        "  summing_logits_I = gLoss_au * MI_cmatrix\n",
        "            \n",
        "  exp_logits = torch.exp(summing_logits)\n",
        "  exp_logits_I = torch.exp(summing_logits_I)\n",
        "  log_sum = torch.sum(exp_logits,0)\n",
        "  print(\"log_sum type: \"+str(type(log_sum)))\n",
        "  print(\"log_sum shape: \"+str(log_sum.shape))\n",
        "  log_sum_I = torch.sum(exp_logits_I,0)\n",
        "    \n",
        "  positive_pair = torch.zeros(batch_size)\n",
        "  positive_pair_I = torch.zeros(batch_size)\n",
        "  \n",
        "  exlogCPU = exp_logits.cpu()\n",
        "  exlogCPU_I = exp_logits_I.cpu()\n",
        "  #lcpu = labels[k].cuda()\n",
        "  #lcpu_ = labels_I[k].cuda()\n",
        "  for l in range(batch_size):\n",
        "    positive_pair[l] = exlogCPU[int(labels[k][l])][l]\n",
        "    positive_pair_I[l] = exlogCPU_I[int(labels_I[k][l])][l]\n",
        "  \n",
        "  positive_pair = positive_pair.cuda()\n",
        "  positive_pair_I = positive_pair_I.cuda()\n",
        "            #positive_pair = torch.exp(torch.mm(positive_pair,gLoss_or))\n",
        "            #positive_pair_I = torch.exp(torch.mm(positive_pair_I,gLoss_au))\n",
        "            \n",
        "  M_logits.append( torch.sum( torch.log(positive_pair/log_sum) ).cpu() ) # +0.0001 ),0).cpu()       ) # check type shape size and len !!!!!!\n",
        "  M_logits_I.append( torch.sum( torch.log(positive_pair_I/log_sum_I) ).cpu() ) # +0.0001 ),0).cpu() ) \n",
        "            \n",
        "result = lb*(-1/M_num)*0.5*( sum(M_logits) + sum(M_logits_I) )\n",
        "\n",
        "# if math.isnan(result): result = 1000000\n",
        "loss = instance_loss + result\n",
        "\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "gLoss_or type: <class 'torch.Tensor'>\n",
            "gLoss_or shape: torch.Size([2, 64])\n",
            "log_sum type: <class 'torch.Tensor'>\n",
            "log_sum shape: torch.Size([64])\n",
            "gLoss_or type: <class 'torch.Tensor'>\n",
            "gLoss_or shape: torch.Size([4, 64])\n",
            "log_sum type: <class 'torch.Tensor'>\n",
            "log_sum shape: torch.Size([64])\n",
            "gLoss_or type: <class 'torch.Tensor'>\n",
            "gLoss_or shape: torch.Size([8, 64])\n",
            "log_sum type: <class 'torch.Tensor'>\n",
            "log_sum shape: torch.Size([64])\n",
            "gLoss_or type: <class 'torch.Tensor'>\n",
            "gLoss_or shape: torch.Size([16, 64])\n",
            "log_sum type: <class 'torch.Tensor'>\n",
            "log_sum shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(107.0621, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMZZyysSZUes",
        "outputId": "746c5826-9b94-4565-c5b3-341e3953a693"
      },
      "source": [
        "#import math\n",
        "#if math.isnan(result): print(\"hit\")\n",
        "\n",
        "#M_logits[3]\n",
        "gLoss_or[15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7720, 0.8382, 0.9848, 0.9325, 0.9402, 0.9391, 0.9725, 0.7768, 0.9377,\n",
              "        0.9297, 0.9822, 0.7676, 0.8109, 0.8661, 0.9301, 0.8629, 0.9385, 0.9184,\n",
              "        0.9419, 0.8366, 0.9571, 0.9364, 0.7582, 0.9660, 0.9743, 0.8421, 0.8107,\n",
              "        0.9721, 0.8074, 0.9561, 0.8316, 0.6752, 0.8958, 0.6500, 0.8663, 0.9596,\n",
              "        0.9185, 0.8886, 0.9598, 0.6563, 0.9769, 0.8240, 0.9089, 0.7385, 0.7065,\n",
              "        0.7262, 0.9192, 0.9111, 0.7214, 0.9165, 0.9661, 0.8357, 0.8414, 0.7493,\n",
              "        0.9021, 0.9420, 0.8866, 0.9535, 0.9483, 0.8401, 0.8741, 0.9685, 0.9406,\n",
              "        0.9285], device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnMUU93g77ql"
      },
      "source": [
        "#losses.update(loss.item())\n",
        "\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "#if i % 25 == 0:\n",
        "#  progress.display(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK15HBx2_qR3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
