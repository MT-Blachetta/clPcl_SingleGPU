# setup
setup: selflabel

# ema
use_ema: False

# Threshold
confidence_threshold: 0.99

# Loss
criterion: confidence-cross-entropy
criterion_kwargs:
   apply_class_balancing: True

# Model
backbone: mnet
num_heads: 1

# Dataset
train_db_name: mnist
val_db_name: mnist
num_classes: 10

# Transformations
augmentation_strategy: ours 
augmentation_kwargs:
   crop_size: 28
   normalize:
      mean: [0.1307]
      std: [0.3081] 
   num_strong_augs: 4
   cutout_kwargs:
     n_holes: 1
     length: 9
     random: True

transformation_kwargs:
   crop_size: 28
   normalize:
      mean: [0.1307]
      std: [0.3081] 

# Hyperparameters
optimizer: adam
optimizer_kwargs:
   lr: 0.0001
   weight_decay: 0.0001
epochs: 100
batch_size: 1000
num_workers: 8

# Scheduler
scheduler: constant